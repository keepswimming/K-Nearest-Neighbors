---
title: "Homework 1 R markdown
author: "Rita Miller"
date: '`r Sys.Date()`'
output:
  word_document:
    fig_height: 4
    fig_width: 4.5
  pdf_document:
    fig_height: 4
    fig_width: 4.5
  html_document:
    fig_height: 4
    fig_width: 4.5
---

```{r setup, include=FALSE}
require(mosaic)   # Load additional packages here 

# Some customization.  You can alter or delete as desired (if you know what you are doing).
#trellis.par.set(theme=theme.mosaic()) # change default color scheme for lattice
knitr::opts_chunk$set(
  echo = TRUE,
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```

Load packages here.
```{r, message=FALSE}
library(ISLR)
library(FNN)
library(ggplot2)
library(dplyr)
library(lattice)
library(mosaic)
```

#### Intellectual Property: 
These problems are the intellectual property of the instructors and may not be reproduced outside of this course.


## Problem 1: Analyzing Gas Mileage  


In this problem, you will use analyze gas mileage using the **Auto** data set from the ISLR library in R.   

#### Question 1 (2 points)

Load the **ISLR** library into R and look at the first few rows of the **Auto** data set.  
```{r}
attach(Auto)
#head(Auto)
```

What data mining strategy would you use to investigate the following questions?  (Note that the orderings for the scenarios and answer choices on Canvas might differ from those shown below.)

*   You are building an app for a used-car website that will take information about the year, engine displacement, and weight of cars, and determine whether they are most likely American (origin = 1), European (2), or Japanese (3). ---> Classification 


*   The manager of a used-car lot wants to arrange groups of similar cars on the lot.  The manager wants to understand the relationships between the year, engine displacement, and weight of cars to identify informative groupings. ----->*Unsupervised 


*   You are building an app for a used-car website that will take information about the year, engine displacement, and weight of cars, and estimate their horsepower. -----> Regression


#### Question 2 (3 points)

We would like to use K-nearest neighbors to predict the gas mileage (`mpg`, miles per gallon) of cars based on their weight (in pounds) and their year of manufacture.  Fill in the blanks:  In this analysis, the main reason why standardizing the data is a (***good/bad) idea is because the variables (mpg and weight, mpg and year, ***weight and year) have very (similar/***different) (means/***standard deviations). 


#### Question 3 (2 points)
Set R's seed to 1 (for Homework 1) with:
**set.seed(1)**

Create a `groups` vector of 256 copies of the number 1 (to represent observations that will be in the training set) and 136 copies of the number 2 (to represent observations that will be in the validation set.  Then use **sample()** to randomize the order of the vector.

Make a vector that contains TRUE for each data point of `Auto` that will be in the training set, and FALSE for each data point that will be in the test (or validation) set.

Enter your R code below.  

**Code Answer**: 
```{r}
groups = c(rep(1, 256), # 1 represents the training set
           rep(2, 136)) #2 represents the validation set
random_groups = sample(groups, 392)
in_train = (random_groups == 1)
```

#### Question 4 (2 points)
Standardize the `weight` and `year` columns of the training set.  Then standardize the `weight` and `year` columns of the test set, *using the original mean and standard deviation of the training set*.

Enter your R code below.  
**Code Answer**: 
```{r}
train_std = scale(Auto[in_train, c("weight", "year")])
test_std = scale(Auto[!in_train, c("weight", "year")],
 center = attr(train_std, "scaled:center"),
 scale = attr(train_std, "scaled:scale"))
```


#### Question 5: **(3 points)**

Use 1-nearest neighbor regression (fit on the standardized training data) to predict the gas mileage of the cars in the standardized validation set.  Compute the mean squared error.  

Enter your R code below.  

**Code Answer**: 
```{r}
K_vals = 1:50
MSE = numeric(length = length(K_vals))

for(ii in 1:length(K_vals)){
 predictions = knn.reg(train = train_std,
 test = test_std,
y = Auto$mpg[in_train],
 k = K_vals[ii])

 MSE[ii] = mean( (predictions$pred - Auto$mpg[!in_train])^2 )
}

gf_line(MSE ~ K_vals, lwd = 2)
```


#### Question 6 (1 point)

What is the MSE for the validation set?  (Round your answer to 2 decimal places.)

Your Answer:  
**Numeric Answer (AUTOGRADED on Canvas)**:  15.25 (with margin: 0.02)



#### Question 7 (4 points)**

Use a for() loop to apply K-nearest neighbors regression to the same training and validation sets, for values of k from 1 to 50.  Make a plot of the MSE (calculated for the validation set predictions) as a function of k.  

Enter your R code and plot on this question on Canvas.  (Use **Insert** -> **Image** to insert the plot.)  
**Code and Graph Answer**: 
```{r}
#see Question 5

```

#### Question 8: **(2 points)**

In your opinion, which value of k is the best choice?  Why?

**Text Answer**: 
The	lowest	MSE	on	the	validation	set	occurs	at	k = 17,	so	this	appears	to	
be	a	good	choice.	Any	k between	about	7	and	25	looks	reasonable.	Note that	with	KNN,	
larger values	of	k actually	produce	lower-variance	models.


## Problem 2:  

In this problem, you will use K-nearest neighbors to classify peopleâ€™s income as >\$50,000 or \$50,000.

You are about to start **Problem 2 of 2**, which analyzes personal income using the Census_income.csv data file (available under Canvas Lesson 1 resources).   You can find more information at [the data source](https://archive.ics.uci.edu/ml/datasets/census+income).  

Data Source:  Kohavi, R and B. Becker. (1996). [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science.  



#### Question 9: (2 points)

Read the data into R.  One-hot encode the variable `Sex`, using `Male` as the default value. (Unfortunately, because this data set is from the US Census, it did not allow allow an option of Intersex, or distinguish between sex and gender.)

Enter your R code below.  
**Code Answer**: 
```{r}
income = read.csv('Census_income.csv')%>%
   mutate(Sex = ifelse(Sex == "Male", 0, 1))
  
```

#### Question 10 (2 points)

Set R's random seed to 1 again.  Then randomly sample 20,000 individuals to be in the training set.

Enter your R code below.  
**Code Answer**: 
```{r}
set.seed(1)
head(income)
dim(income)
train = sample(1:32561, 20000, replace = F) #As discussed in https://piazza.com/class/ksopdbdngd46ip?cid=97, this approach works fine when you're not trying to match the autograder, but it doesn't prepare you as well for doing cross-validation in lesson 2.
```


#### Question 11 (2 points)
Standardize the EducYears and Age variables from the training data.  Combine these with the unstandardized, one-hot encoded Sex variable from the training data to create a data frame `x_train`.

Use the original means and standard deviations from the training data to standardize EducYears and Age from the validation data.  Combine these with the unstandardized, one-hot encoded Sex variable to create a data frame `x_test`. 

Enter your R code below.  
**Code Answer**: 
```{r}

#create new column called sex01
income["sex01"] = as.factor(ifelse(income$Sex== " Male",0,1))
table(income$sex01)
```

```{r}
x_train = income[train, ]#create new df pulling training data using the training indices
```
```{r}
Educ.train.std = scale(x_train$EducYears) #Standardize the EducYears and Age variables from the training data
```
```{r}
Age.train.std = scale(x_train$Age)
```

```{r}
#Combine these with the unstandardized, one-hot encoded Sex variable to create a data frame `x_test`. 
x_train.std = data.frame(Educ.train.std, Age.train.std, x_train$sex01)
```
```{r}
#Combine these with the unstandardized, one-hot encoded Sex variable to create a data frame `x_test`. 
x_test = income[-train,] 

# Use the original means and standard deviations from the training data to standardize EducYears and Age from the validation data.
Educ.test.std = scale(x_test$EducYears,center = attr(Educ.train.std, "scaled:center"),scale = attr(Educ.train.std, "scaled:scale"))
#standardize the age variable
Age.test.std = scale(x_test$Age,center = attr(Age.train.std, "scaled:center"),scale = attr(Age.train.std, "scaled:scale"))
#combine the standardized values from the training set, with the sex01 values from the remaining indices
x_test.std = data.frame(Educ.test.std, Age.test.std, x_test$sex01)
```
```

#### Question 12 (2 points)

Use 25-nearest neighbor classification (fit on the training set) to predict whether the income of each individual in the validation set is >50K or <=50K. 

Find the confusion matrix.  You should be able to produce a matrix table with two rows and two columns, similar to the one below. 

Please enter the information as whole numbers.  Note carefully the labels for the rows and columns, and be sure to orient your table accordingly.



Please enter the information *exactly as it appears in R*.

.                 | Actual income <= 50K | Actual Income > 50K
----------------- | -------------------- | -------------------
Classified <= 50K	| **[A]** | **[B]** | 
Classified > 50K	| **[C]** | **[D]** | 
	

**Numeric Answer (AUTOGRADED on Canvas)**:  
[A] =  8782 
[B] =  1691 
[C] =  814 
[D] =  1274 




#### Question 13 (1 point)

What is the overall error rate on the validation set? Enter your answer as a decimal between 0 and 1, rounded to 4 decimal places.


**Numeric Answer (AUTOGRADED on Canvas)**:0.1994 (with margin: 0.0001)
19.94 (with margin: 0.01)


#### Question 14 (1 point)

What proportion of people making > $50,000 were misclassified? Enter your answer as a decimal between 0 and 1, rounded to 4 decimal places.


**Numeric Answer(AUTOGRADED on Canvas)**:0.5703 (with margin: 0.0001)
57.03 (with margin: 0.01)

 
#### Question 15 (2 points)
Make a grid of example points with values of education from 1 to 16, ages from 17 to 75, and sex from 0 to 1.  Standardize education and age using the original mean and standard deviation of the training set (from question 11).

Create a data frame, `x_example`, containing the standardized education and age and the unstandardized sex from the example points.  The order of the columns should match the order of the columns in `x_train`.

Enter your R code below.  
**Code Answer**: 
```{r}
###age filter
x_example <- expand.grid(EducYears = seq(1, 16, 1), Age = seq(17,75,1),
            sex = c(0,1))
nrow(x_example)
Educ.example.std = scale(x_example$EducYears,center = attr(Educ.train.std, "scaled:center"),scale = attr(Educ.train.std, "scaled:scale"))
#standardize the age variable
Age.example.std = scale(x_example$Age,center = attr(Age.train.std, "scaled:center"),scale = attr(Age.train.std, "scaled:scale"))
#combine the standardized values from the training set, with the sex01 values from the remaining indices
x_example.std = data.frame(Educ.example.std, Age.example.std, x_example$sex)

```

#### Question 16 (2 points)
Use 25-nearest neighbors to predict the income classifications of the example points, using the same training data as in question 12.  Make graphs showing the relationship between education, age, sex, and predicted income.

Use **Insert** -> **Image** to upload your graphs to this question on Canvas. 


**Graph Answer**:
```{r}
predictions = knn(train = x_train,
 test = x_example,
 cl = income$Income[in_train],
 k = 25)
x_example <- example_data %>%
 mutate(pred = predictions) %>%
 rename(EducYears = Var1,
 Age = Var2,
 Sex = Var3)
x_example %>%
 filter(Sex == 0) %>%
 gf_point(EducYears ~ Age, color =~ pred) %>%
 gf_labs(title = "01")

```
```{r}
x_example %>%
 filter(Sex == 1) %>%
 gf_point(EducYears ~ Age, color =~ pred) %>%
 gf_labs(title = "02")
```


#### Question 17 (3 points)
Write 3-6 sentences interpreting the graphs you made in the previous question.  (For purposes of interpreting the results, note that the data are from the 1990s.)

**Text Answer**: 
	Men	age	28	and	older	with	high	levels	of	education	(beyond	a	high	
school	diploma)	tend	to	be	predicted	to	have	high	incomes	(>50K).	There	is	a	narrower	age	
band	of	around	40-60	years	old	in	which	men	with	only	a	high	school	diploma,	or	less,	often	
have	high	incomes.	This	suggests	that	for	men,	experience	in	a	job	can	substitute	for	high	
levels	of	education,	in	terms	of	obtaining	a	good	income.	This	effect	doesnâ€™t	hold	for	men	
above	about	age	60,	which	may	indicate	that	they	are	partly	retired,	or	possibly	subject	to	
age-based	discrimination.
In	contrast,	women	are	only	predicted	to	have	a	high	income	if	their	age	is	in	the	range	of	
about	30-60	and they	have	a	high	level	of	education.	This	suggests	that	women	need	both
experience	in	a	job	and	high	levels	of	education	to	earn	a	good	income.
